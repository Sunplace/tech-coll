# Temp space

## llm runtime
https://medium.com/@kailaspsudheer/the-transformers-arithmetic-527111099527

https://christophergs.com/blog/intro-to-large-language-models-llms

https://vevesta.substack.com/p/choose-llm-with-optimal-runtime-performance-using-etalon

## saml
https://github.com/IdentityPython/pysaml2/tree/master

https://github.com/SAML-Toolkits/python-saml/blob/master/demo-flask/index.py

https://github.com/abarto/flask-pysaml2-example

## to do list
saml

baai 模型

gcp

kind

vector

loki

telegraf + kafka + telegraf + Prometheus

text embedding

rag

https://github.com/labring/FastGPT

https://github.com/langchain-ai/langgraph-studio

https://github.com/langchain-ai/langchain

https://github.com/microsoft/graphrag

https://github.com/run-llama/llama_index

https://github.com/infiniflow/ragflow

https://github.com/open-webui/open-webui

https://github.com/langgenius/dify

提示词工程

微调的原理，作用，适用场景，实现。

dify

fastgpt

llm Top P, Temperature

langchain langgraph 接口访问 llm，embedding，rerank
大模型 benchmark

vllm 分布式
xinference 分布式
微调的方法，作用与意义
分布式推理 是否必须nccl或者gool gpu直通
模型针对相同问题不同的回答

multiple process share single gpu

https://cloud.tencent.com/document/product/457/116720
https://cloud.tencent.com/document/product/457/116254
https://docs.sglang.ai/references/multi_node.html
https://github.com/sgl-project/sglang/issues/748
https://raw.githubusercontent.com/kubernetes-sigs/lws/refs/heads/main/docs/examples/vllm/build/ray_init.sh
https://github.com/vllm-project/vllm/issues/13521
https://github.com/vllm-project/vllm/blob/main/examples/online_serving/run_cluster.sh

sglang 及其lws分布式
微调的方法、作用及意义